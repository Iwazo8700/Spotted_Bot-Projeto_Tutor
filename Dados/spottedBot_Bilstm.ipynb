{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spottedBot-Bilstm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGcjt1xJUF0I"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import random as rd\n",
        "import sys\n",
        "import io\n",
        "import logging, os\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import LambdaCallback"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laYuRo7kUH6D",
        "outputId": "a3ac2078-3f0c-4b83-8dd8-2d819e9f4ffb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "arquivo = pd.read_csv(\"Spotteds.csv\")\n",
        "\n",
        "\n",
        "arquivo_em_minusculo = arquivo.Documentos.str.lower()\n",
        "minusculo_sem_acento = arquivo_em_minusculo.str.normalize('NFKD').str.encode('ascii', errors = 'ignore').str.decode('utf-8')\n",
        "dados = minusculo_sem_acento.drop([17642, 17848, 17852, 17979, 18488, 24311])\n",
        "spotteds_string = ''\n",
        "for spotteds in dados:\n",
        "  spotteds_string += spotteds\n",
        "\n",
        "\n",
        "spotteds_set = set(spotteds_string)\n",
        "spotteds_lista = sorted(list(spotteds_set))\n",
        "\n",
        "\n",
        "# tipo a é 0, b é 1?? aham\n",
        "\n",
        "dic = dict(enumerate(spotteds_lista))\n",
        "print(dic)\n",
        "\n",
        "dicionario_invertido = {v: k for k, v in dic.items()} # tem uma virgula. isso. VLw man\n",
        "\n",
        "print(dicionario_invertido['f'])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: ' ', 1: '!', 2: '\"', 3: '#', 4: '$', 5: '%', 6: '&', 7: \"'\", 8: '(', 9: ')', 10: '*', 11: '+', 12: ',', 13: '-', 14: '.', 15: '/', 16: '0', 17: '1', 18: '2', 19: '3', 20: '4', 21: '5', 22: '6', 23: '7', 24: '8', 25: '9', 26: ':', 27: ';', 28: '=', 29: '?', 30: '@', 31: 'M', 32: 'N', 33: 'T', 34: '[', 35: '\\\\', 36: ']', 37: '^', 38: '_', 39: 'a', 40: 'b', 41: 'c', 42: 'd', 43: 'e', 44: 'f', 45: 'g', 46: 'h', 47: 'i', 48: 'j', 49: 'k', 50: 'l', 51: 'm', 52: 'n', 53: 'o', 54: 'p', 55: 'q', 56: 'r', 57: 's', 58: 't', 59: 'u', 60: 'v', 61: 'w', 62: 'x', 63: 'y', 64: 'z', 65: '{', 66: '|', 67: '}', 68: '~'}\n",
            "44\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouU66uwbUMxw"
      },
      "source": [
        "maxlen = 40\n",
        "step = 3\n",
        "entrada = []\n",
        "saida = []\n",
        "for i in dados:\n",
        "  for j in range(0, len(i) - maxlen, step):\n",
        "    entrada.append(i[j: j + maxlen])\n",
        "    saida.append(i[j + maxlen])\n",
        "\n",
        "entradaBi = []\n",
        "saidaBi = []\n",
        "for i in dados: #fazendo a leitura bilateral (de traz pra frente)\n",
        "  for j in range(len(i), maxlen, -step):\n",
        "    frase = i[j - maxlen: j]\n",
        "    frase = frase[:: -1]\n",
        "    entradaBi.append(frase) \n",
        "    saidaBi.append(i[j - maxlen - 1])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM8dbairU0N_"
      },
      "source": [
        "vetor_x = np.zeros((len(entrada), maxlen, len(spotteds_lista)), dtype=np.bool)\n",
        "vetor_y = np.zeros((len(saida), len(spotteds_lista)), dtype=np.bool)\n",
        "vetor_xBi = np.zeros((len(entradaBi), maxlen, len(spotteds_lista)), dtype=np.bool)\n",
        "vetor_yBi = np.zeros((len(saidaBi), len(spotteds_lista)), dtype=np.bool)\n",
        "\n",
        "for i in range(len(vetor_x)):# percorre as frases \n",
        "  for j in range(len(vetor_x[i])): #percorre cada caracter\n",
        "    caracter = entrada[i][j]\n",
        "    indice = dicionario_invertido[caracter]\n",
        "    vetor_x[i][j][indice] = 1\n",
        "\n",
        "for k in range(len(vetor_y)):\n",
        "  caracter = saida[k]\n",
        "  indice = dicionario_invertido[caracter]\n",
        "  vetor_y[k][indice] = 1\n",
        "\n",
        "for i in range(len(vetor_xBi)):# percorre as frases \n",
        "  for j in range(len(vetor_xBi[i])): #percorre cada caracter\n",
        "    caracter = entradaBi[i][j]\n",
        "    indice = dicionario_invertido[caracter]\n",
        "    vetor_xBi[i][j][indice] = 1\n",
        "    \n",
        "for k in range(len(vetor_yBi)):\n",
        "  caracter = saidaBi[k]\n",
        "  indice = dicionario_invertido[caracter]\n",
        "  vetor_yBi[k][indice] = 1"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4JDL4paVxSy"
      },
      "source": [
        "modeloBi = Sequential()\n",
        "modeloBi.add(LSTM(256, input_shape = (maxlen, len(spotteds_lista))))\n",
        "modeloBi.add(Dense(len(spotteds_lista), activation='softmax'))\n",
        "\n",
        "\n",
        "modelo = Sequential()\n",
        "modelo.add(LSTM(256, input_shape = (maxlen, len(spotteds_lista))))\n",
        "modelo.add(Dense(len(spotteds_lista), activation='softmax'))\n",
        "\n",
        "\n",
        "modeloBi.compile(loss='categorical_crossentropy',optimizer='adam')\n",
        "\n",
        "modelo.compile(loss='categorical_crossentropy',optimizer='adam')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzeWhuMtV6uO"
      },
      "source": [
        "def amostra(neuronio, temp):\n",
        "  neuronio_array = np.asarray(neuronio).astype('float64')\n",
        "  neuronio_log = np.log(neuronio_array)/ temp\n",
        "  neuronio_exp = np.exp(neuronio_log)\n",
        "  neuronio_divisao = neuronio_exp/ np.sum(neuronio_exp)\n",
        "  prob = np.random.multinomial(1, neuronio_divisao, 1)\n",
        "  return np.argmax(prob)\n",
        "\n",
        "\n",
        "def print_epoch(epoch):\n",
        "  print(epoch)\n",
        "  index = rd.randint(0, len(entrada))\n",
        "  frase_atual = entrada[index]\n",
        "  temperaturas = [0.2, 0.5, 1, 1.2]\n",
        "\n",
        "  for temp in temperaturas:\n",
        "    print(frase_atual, end = \"\")\n",
        "    frase_aux = frase_atual\n",
        "    for n_caracteres in range(50):\n",
        "      vetor_x = np.zeros(1, (maxlen, len(spotteds_lista)), dtype=np.bool)\n",
        "      for j in range(len(vetor_x[0])): #percorre cada caracter\n",
        "        caracter = frase_aux[0][j]  #cria uma entrada binaria pra rede\n",
        "        indice = dicionario_invertido[caracter]\n",
        "        vetor_x[0][j][indice] = 1\n",
        "        \n",
        "      retorno = modelo.predict(vetor_x, verbose = 0)[0]\n",
        "      indice_caracter = amostra(retorno, temp) #dada uma temperatura, recebemos o indice do proxmo caracter\n",
        "      caracter_atual = dicionario_invertido[indice_caracter]\n",
        "      print(caracter_atual, end=\"\")\n",
        "      frase_aux = frase_aux[1:]\n",
        "      frase_aux = frase_aux + caracter_atual\n",
        "  print()\n",
        "\n",
        "#entrada -> Eu sou baralho\n",
        "#entradaBi -> ohlarab uos uE\n",
        "\n",
        "def print_epochBi(epoch):\n",
        "  print(epoch)\n",
        "  index = rd.randint(0, len(entradaBi))\n",
        "  frase_atual = entradaBi[index]\n",
        "  temperaturas = [0.2, 0.5, 1, 1.2]\n",
        "\n",
        "  for temp in temperaturas:\n",
        "    print(frase_atual, end = \"\")\n",
        "    frase_aux = frase_atual\n",
        "    for n_caracteres in range(50):\n",
        "      vetor_x = np.zeros(1, (maxlen, len(spotteds_lista)), dtype=np.bool)\n",
        "      for j in range(len(vetor_x[0])): #percorre cada caracter\n",
        "        caracter = frase_aux[0][j]  #cria uma entrada binaria pra rede\n",
        "        indice = dicionario_invertido[caracter]\n",
        "        vetor_x[0][j][indice] = 1\n",
        "        \n",
        "      retorno = modeloBi.predict(vetor_x, verbose = 0)[0]\n",
        "      indice_caracter = amostra(retorno, temp) #dada uma temperatura, recebemos o indice do proxmo caracter\n",
        "      caracter_atual = dicionario_invertido[indice_caracter]\n",
        "      print(caracter_atual, end=\"\")\n",
        "      frase_aux = frase_aux[1:]\n",
        "      frase_aux = frase_aux + caracter_atual\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEaMksLrV9Qc"
      },
      "source": [
        "logging.disable(logging.WARNING)\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "\n",
        "\n",
        "arquivo_caminho = 'pesos{epoch:02d}-{loss: .2f}.hdf5'\n",
        "\n",
        "checkpoints = ModelCheckpoint(arquivo_caminho, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=print_epoch)\n",
        "lista_callbacks = [checkpoints, print_callback]\n",
        "\n",
        "modelo.fit(vetor_x, vetor_y, batch_size=128, epochs=25, callbacks=lista_callbacks)\n",
        "\n",
        "modeloBi.fit(vetor_xBi, vetor_yBi, batch_size=128, epochs=25, callbacks=lista_callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNhk1nt4WBDF"
      },
      "source": [
        "def testefinal(frase):\n",
        "  print(frase, end=\"\")\n",
        "  frase_aux = frase\n",
        "  frase_inv = frase[::-1]\n",
        "  for n_caracteres in range(50):\n",
        "    vetor_x = np.zeros(1, (maxlen, len(spotteds_lista)), dtype=np.bool)\n",
        "    for j in range(len(vetor_x[0])): #percorre cada caracter\n",
        "        caracter = frase_aux[0][j]  #cria uma entrada binaria pra rede\n",
        "        indice = dicionario_invertido[caracter]\n",
        "        vetor_x[0][j][indice] = 1\n",
        "    retorno = modelo.predict(vetor_x, verbose = 0)[0]\n",
        "    indice_caracter = amostra(retorno, temp)\n",
        "    caracter_atual = dicionario_invertido[indice_caracter]\n",
        "    print(caracter_atual, end=\"\")\n",
        "    frase_aux = frase_aux[1:]\n",
        "    frase_aux = frase_aux + caracter_atual\n",
        "  \n",
        "    vetor_xBi = np.zeros(1, (maxlen, len(spotteds_lista)), dtype=np.bool)\n",
        "    for j in range(len(vetor_xBi[0])): #percorre cada caracter\n",
        "        caracter = frase_inv[0][j]  #cria uma entrada binaria pra rede\n",
        "        indice = dicionario_invertido[caracter]\n",
        "        vetor_xBi[0][j][indice] = 1\n",
        "    retorno = modeloBi.predict(vetor_xBi, verbose = 0)[0]\n",
        "    indice_caracter = amostra(retorno, temp)\n",
        "    caracter_atual = dicionario_invertido[indice_caracter]\n",
        "    frase_inv = frase_inv[1:]\n",
        "    frase_inv = frase_inv + caracter_atual\n",
        "    print(caracter_atual, end=\"\")\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}